# MBDA TFM - Zygarde Job Executor

Una de las aplicaciones más comunes de las técnicas de aprendizaje automático es la generación de modelos que permiten emitir predicciones sobre tareas de clasificación o regresión. La construcción de estos modelos se lleva a cabo mediante algoritmos que realizan un entrenamiento sobre grandes volúmenes de datos, representativos del universo de discurso a inferir. Cada una de estas técnicas, a su vez, suele poseer una serie de parámetros de configuración cuyos valores también determinan y condicionan el funcionamiento del algoritmo, siendo perentorio hallar la combinación óptima que lleve a producir el mejor modelo posible sobre el conjunto de datos proporcionado. Debido al elevado volumen de datos necesario para construir un modelo capaz de efectuar predicciones precisas en un escenario de cierta complejidad, unido al proceso de prueba y error necesario para identificar el algoritmo idóneo y la configuración de hiperparámetros óptima, el entrenamiento de estos modelos se constituye como un proceso que requiere una gran cantidad de recursos y tiempo de cómputo.

Tradicionalmente, la ejecución de procesos con grandes necesidades de recursos computacionales se ha llevado a cabo en súper-computadores que, por los costes de su adquisición y mantenimiento, sólo estaban a disposición de las instituciones gubernamentales, militares y académicas. En este contexto, las técnicas de computación distribuida posibilitan la división de los procesos de cómputo en unidades más reducidas y su reparto entre diferentes computadores de menor potencia interconectados en red, lo que permite la ejecución de estos procesos de cómputo intensivo empleando equipos asequibles. El advenimiento de las tecnologías en la nube, y particularmente la irrupción de los proveedores públicos de _cloud_, ha traído consigo la capacidad de ejecutar procesos de cómputo sin necesidad de realizar una inversión previa en infraestructura, mediante un modelo de pago por despliegue o de pago por uso sobre los recursos hardware aprovisionados.

La propuesta del presente Trabajo Final de Máster es el diseño e implementación de una plataforma gestionada en la nube y dirigida por eventos para el entrenamiento bajo demanda de modelos de aprendizaje automático. Su principal finalidad es automatizar la selección de la técnica de aprendizaje y la configuración de hiperparámetros óptimas mediante la ejecución paralela de diferentes combinaciones de las mismas, construyendo el modelo más preciso para la resolución de un problema. Para ello, se sirve de implementaciones distribuidas y escalables de los algoritmos de aprendizaje automático y de la disponibilidad de recursos por parte del proveedor _cloud_. La adopción de esta plataforma permite obtener dos importantes ventajas: la reducción del tiempo total de entrenamiento y una gestión inteligente de los recursos aprovisionados, adquiriéndolos y liberándolos dinámicamente en función de la carga de trabajo del sistema y pagando sólo por su tiempo de uso efectivo.

---

**Palabras clave:** aprendizaje automático, arquitectura _cloud_, computación distribuida.
